---
title: "STAT380_HW8"
author: Nicholas Way
output: html_document
date: "Due: Due on Monday, November 27 (Grace Period: Typical 9 Hours)"
---

## Instructions

In class, we introduced 3 methods for selecting the features to be included in a model (forward, backward, LASSO). The activities that follow are meant to provide further practice with these concepts. NOTE: All required `library` commands **must be** included in the Front Matter section. If you include your `library` commands elsewhere in your code, you will be penalized.

At the conclusion to the activity, you should upload

1.  your .html file named LastnameFirstInitial_STAT380_HW8.html
2.  your .Rmd file named LastnameFirstInitial_STAT380_HW8.Rmd

## Learning Objectives
This assignment address aspects of the following learning objectives.

1. Students will be able to load datasets from R packages and external sources into the R environment.
2. Given a statistical learning method, students will be able to restructure the data for use in the corresponding R function.
3.	Identify the best subset of predictors for a linear regression model using subset selection methods, such as best subsets or stepwise regression, using statistical software.
4. Apply shrinkage/regularization methods for estimating parameters using statistical software, including selecting a value for the tuning parameter using cross validation.
5. Interpret the results of LASSO in the context of feature selection.
6. Compare the ability of competing models to generalize for new data.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter - Clean Environment, Load Libraries, User Defined Functions

```{r}
rm(list = ls())

#Load Packages
library(tidyverse)
library(glmnet) #To perform LASSO and Ridge

MLB <- read.csv("C:/Users/nicho/OneDrive - The Pennsylvania State University/Stat 380/Homework/MLB.csv")
```


## Problem 1. Baseball Data 

`MLB.csv` contains information about a sample of Major League Baseball (MLB) players from the 1986 and 1987 seasons. Variables include:

* PlayerName-Player’s name
* AtBat-Number of times at bat in 1986
* Hits-Number of hits in 1986
* HmRun-Number of home runs in 1986
* Runs-Number of runs in 1986
* RBI-Number of runs batted in in 1986
* Walks-Number of walks in 1986
* Years-Number of years in the major leagues
* CAtBat-Number of times at bat during his career
* Chits-Number of hits during his career
* CHmRun-Number of home runs during his career
* CRuns-Number of runs during his career
* CRBI-Number of runs batted in during his career
* CWalks-Number of walks during his career
* League-factor with levels A (for American) and N (for National) indicating player's league at the end of 1986
* Division-factor with levels E (for East) and W (for West) indicating player's division at the end of 1986
* PutOuts-Number of put outs in 1986
* Assists-Number of assists in 1986
* Errors-Number of errors in 1986
* Salary-1987 annual salary on opening day in thousands of dollars
* NewLeague-factor with levels A (for American) and N (for National) indicating player's league at the beginning of 1987

**Our goal is to predict a baseball player’s 1987 salary on the basis of the other variables in the dataset (excluding player name).**

a. Remove the `PlayerName` column and any players with a missing salary. Name the result `MLB2`. NOTE: `MLB2` should have 263 observations and 20 variables.

```{r}
MLB2 <- MLB %>% select(-PlayerName)
MLB2 <- MLB2 %>% filter(!is.na(Salary))
```

b. In order to use the `glmnet` and/or `cv.glmnet` function for building LASSO regression models, create the input matrix and response variable vector. 

```{r}
Xmat <- model.matrix(Salary ~ ., data = MLB2)[,-1]
yvec <- MLB2$Salary
```

c. Using a seed of 321, perform an 85/15 training/validation split.

```{r}
set.seed(321)
trainInd <- sample(1:nrow(MLB2), floor(.85*nrow(MLB2)))
set.seed(NULL)

XmatTrain <- Xmat[trainInd, ]
XmatVal <- Xmat[-trainInd, ]
yvecTrain <- yvec[trainInd]
yvecVal <- yvec[-trainInd]
```

d. Using a seed of 12345 and 10-fold cross validation on the training data, use the `cv.glmnet` function to create the plot of MSE as a function of $log(\lambda)$. NOTE: The seed mentioned in this problem should not be used to repeat the training/validation split. Instead, it is the seed for the `cv.glmnet` function which will do the 10-fold cross validation for you.

```{r}
#Use 10-fold CV to pick lambda for LASSO (use seed 123)
set.seed(12345)
lassoCV <- cv.glmnet(x = XmatTrain, y = yvecTrain, family = "gaussian", alpha = 1, lambda = NULL,
                     standardize = TRUE, nfolds = 10)
set.seed(NULL)
#Show the LASSO CV results
plot(lassoCV)
```


e. What is the optimal $\lambda$ for LASSO regression based on using the minimum value of MSE rule? Which variables are included using this value of $\lambda$? 

```{r}
lassoCV$lambda.min

coefLamMin <- predict(lassoCV, s = lassoCV$lambda.min, type = "coefficients")

tempdf1 <- 
  data.frame(Variable = row.names(coefLamMin), 
             lamMin = as.numeric(coefLamMin))

tempdf1
```

The optimal $\lambda$ for LASSO regression based on using the minimum value of MSE rule is 2.333354. The varaibles that are included using this $\lambda$ value are AtBat, Hits, HmRun, Runs, Walks, Years, CRuns, CRBI, CWalks, LeagueN, DivisionW, PutOuts, Assists, and Errors. These are the variables with coefficients greater than 0.

f. What is the optimal $\lambda$ for LASSO regression based on using the 1-standard error (1SE) rule? Which variables are included using this value of $\lambda$? 

```{r}
lassoCV$lambda.1se

coefLam1se <- predict(lassoCV, s = lassoCV$lambda.1se, type = "coefficients")

tempdf2 <- 
  data.frame(Variable = row.names(coefLamMin), 
             lam1se = as.numeric(coefLam1se))

tempdf2
```

The optimal $\lambda$ for LASSO regression based on using the 1-standard error (1SE) rule is 87.84927. The varaibles that are included using this $\lambda$ value are Hits, Walks, CRuns, CRBI, and PutOuts. These are the variables with coefficients greater than 0.

g. Using the value of $\lambda$ associated with the minimum MSE, compute **and interpret** the RMSE on validation data.

```{r}
lassoYhat <- predict(lassoCV, s = lassoCV$lambda.min, newx = XmatVal)
lassoMSE <- mean((yvecVal - lassoYhat)^2)
lassoRMSE <- sqrt(lassoMSE)
lassoRMSE
```

The calculated RMSE is 310.1718. In this context, the RMSE  means on average, our model's predicted salaries differ from the actual salaries by approximately 310.1718 or $310.17. 

h. If you were to perform backward elimination for selecting the "best" subset of predictors for predicting salary, which variables would remain in the model?

```{r}
int_only_model <- lm(Salary ~ 1, data = MLB2)

full_model <- lm(Salary ~ ., data = MLB2)

stats::step(object = full_model, 
            scope = list(lower = int_only_model, upper = full_model),
            data = MLB2,
            direction = "backward")
```

After performing backward elimination, the variables that remain are AtBat, Hits, Walks, CAtBat, CRuns, CRBI, CWalks, Division, PutOuts, and Assists.

i. Based on the RMSE for the validation data, which model (the model selected by LASSO regression with $\lambda$ based on the minimum MSE OR the model selected by backward elimination) produced a better RMSE on the validation data? Justify your answer. (Your answer should inclue the RMSE for both models.)

```{r}
Train <- MLB2[trainInd, ]
Validation <- MLB2[-trainInd, ]

lmModel <- lm(Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + 
    CRBI + CWalks + Division + PutOuts + Assists, data = MLB2)

lmYhat <- predict(lmModel, newdata = Validation)  
lmMSE <- mean((yvecVal - lmYhat)^2)
lmRMSE <- sqrt(lmMSE)
lmRMSE
lassoRMSE
```

The RMSE using the lasso regression method is 310.1718 and the RMSE using backward elimination method is 271.4275. Ideally we want the smallest RMSE value possible, because it measures the average difference between predicted and actual values. In other words, a lower RMSE indicates better model performance in terms of prediction accuracy. Since the backward elimination RMSE value is lower than the lasso regression value (271<310), the backward elimination model produces a better RMSE.
